{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P1pe8w9f-n1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import keras\n",
        "#sklearn import iris\n",
        "from keras.datasets import mnist\n",
        "from sklearn.datasets import load_iris\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD4an4nJgGL1",
        "outputId": "356b88e1-580c-4b91-96df-b9436de976f8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Load the data and seperate it into the trainning and testing section\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "feat_names = iris.feature_names\n",
        "x_iris = iris.data\n",
        "y_iris = iris.target\n",
        "x_iris_pd = pd.DataFrame(x_iris, columns = feat_names)\n",
        "y_iris_pd = pd.DataFrame(y_iris, columns = [\"target\"])\n",
        "x_iris_train, x_iris_test, y_iris_train, y_iris_test = train_test_split(x_iris, y_iris, test_size = .3, random_state = 42)\n",
        "\n",
        "# This is the data (x)\n",
        "print('Number of train examples:', x_iris_train.shape)\n",
        "print('Number of test examples:', x_iris_test.shape)\n",
        "\n",
        "# these represent the ouput for the data (y)\n",
        "print('Number of train features:', y_iris_train.shape)\n",
        "print('Number of test features:', y_iris_test.shape)\n",
        "\n",
        "#print(y_train)\n",
        "# The reason we have the data broken up into two sections is to update the model (train)\n",
        "# and then see how well it preforms with new information (testing)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train examples: (105, 4)\n",
            "Number of test examples: (45, 4)\n",
            "Number of train features: (105,)\n",
            "Number of test features: (45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U8i4e4RFmdt",
        "outputId": "bd707e85-eb53-4c87-ec6d-9873f0672c31"
      },
      "source": [
        "print(x_iris_pd.head())\n",
        "print(y_iris_pd.value_counts())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "target\n",
            "2         50\n",
            "1         50\n",
            "0         50\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7wiprW4gKe0",
        "outputId": "3039d7ef-fa69-452c-f1d6-0dda36ebbff3"
      },
      "source": [
        "'''\n",
        "# Get the number of pixels in the Neural Network\n",
        "image_size = 784\n",
        "features = 4\n",
        "\n",
        "# Reduce the dimensionality of the data\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size) # Transform from matrix to vector\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255 # Normalize inputs from 0-255 to 0.0-1.0\n",
        "'''\n",
        "\n",
        "x_iris_train = x_iris_train.reshape(x_iris_train.shape[0], features).astype('float32')\n",
        "x_iris_train = (x_iris_train - x_iris_train.min())/(x_iris_train.max() - x_iris_train.min())\n",
        "#print(x_iris_train)\n",
        "\n",
        "\n",
        "'''\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size) # Transform from matrix to vector\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255 # Normalize inputs from 0-255 to 0.0-1.0\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "'''\n",
        "classes = 3\n",
        "y_iris_train = tf.keras.utils.to_categorical(y_iris_train, classes)\n",
        "y_iris_test = tf.keras.utils.to_categorical(y_iris_test, classes)\n",
        "\n",
        "\n",
        "print('Number of train examples:', x_iris_train.shape)\n",
        "print('Number of test examples:', x_iris_test.shape)\n",
        "print('Number of train features:', y_iris_train.shape)\n",
        "print('Number of test features:', y_iris_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train examples: (105, 4)\n",
            "Number of test examples: (45, 4)\n",
            "Number of train features: (105, 3)\n",
            "Number of test features: (45, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOGudU1qgRZ6"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, InputLayer\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrbLcPFNhHdP"
      },
      "source": [
        "# sequential is a type of feed forward model\n",
        "model = Sequential(\n",
        "            [\n",
        "                # fully connected layer with 32 nodes, takes in 28*28 input images\n",
        "                Dense(32, input_shape=(28*28,), activation='linear'),\n",
        "                # another fully connected layer with 5 nodes\n",
        "                Dense(5, activation='linear'),\n",
        "                # another fully connected layer with 5 nodes\n",
        "                Dense(10, activation='linear')\n",
        "            ]\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ITDkLSTNvdF"
      },
      "source": [
        "model_iris = Sequential(\n",
        "            [\n",
        "                # fully connected layer with 10 nodes, takes in 4 inputs\n",
        "                Dense(7, input_shape=(4,), activation='relu'),\n",
        "                # another fully connected layer with 3 nodes\n",
        "                Dense(300, activation='relu'),\n",
        "                Dense(300, activation='relu'),\n",
        "                Dense(3, activation='relu')\n",
        "            ]\n",
        "                  )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmK3SjvQhLBg"
      },
      "source": [
        "model_iris.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLgi-D68hN7k"
      },
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T8p7ZathT6n"
      },
      "source": [
        "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=256, epochs=5, verbose=True, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl4P0w9XOhqu",
        "outputId": "d418ffa8-d187-4aef-a3f4-37dcb800d134"
      },
      "source": [
        "model_iris.compile(optimizer = \"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_iris = model_iris.fit(x_iris_train, y_iris_train, epochs = 50, verbose=True, validation_split=.1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 1s 147ms/step - loss: 1.2889 - accuracy: 0.3105 - val_loss: 1.3058 - val_accuracy: 0.1818\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.1478 - accuracy: 0.3261 - val_loss: 1.1681 - val_accuracy: 0.1818\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.0804 - accuracy: 0.3105 - val_loss: 1.0993 - val_accuracy: 0.1818\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0390 - accuracy: 0.3183 - val_loss: 1.0479 - val_accuracy: 0.2727\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.0255 - accuracy: 0.6252 - val_loss: 1.0066 - val_accuracy: 0.5455\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9983 - accuracy: 0.6281 - val_loss: 0.9694 - val_accuracy: 0.5455\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.9742 - accuracy: 0.6196 - val_loss: 0.9342 - val_accuracy: 0.6364\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9537 - accuracy: 0.4741 - val_loss: 0.8964 - val_accuracy: 0.6364\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9157 - accuracy: 0.6065 - val_loss: 0.8532 - val_accuracy: 0.9091\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.8804 - accuracy: 0.7108 - val_loss: 0.7993 - val_accuracy: 0.9091\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.8316 - accuracy: 0.8818 - val_loss: 0.7263 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7539 - accuracy: 0.9343 - val_loss: 0.6466 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6601 - accuracy: 0.9592 - val_loss: 0.5491 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5452 - accuracy: 0.9553 - val_loss: 0.4122 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4106 - accuracy: 0.9461 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2159 - accuracy: 0.9393 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9634 - accuracy: 0.8318 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.9113 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.2871 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.3300 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.3066 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.3105 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.3144 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.3261 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.3105 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.3183 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3300 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.2949 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3222 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2597 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.2988 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.2753 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3378 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2832 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.2675 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.3027 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.3144 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.3535 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.3418 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3105 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2949 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3339 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.3105 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.3300 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: nan - accuracy: 0.3183 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: nan - accuracy: 0.2597 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.3183 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.2910 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.2871 - val_loss: nan - val_accuracy: 0.1818\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.2988 - val_loss: nan - val_accuracy: 0.1818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtlcLVyqhZfl"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation('relu'))                            \n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijLAFAXhlyI"
      },
      "source": [
        "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=256, epochs=10, verbose=True, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}