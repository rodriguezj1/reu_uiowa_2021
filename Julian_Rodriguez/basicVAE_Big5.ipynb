{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basicVAE_Big5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXAtuoWfCvl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875fe064-3740-4267-eae2-024a2b475c10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCSXEz5ACCh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils.vis_utils import plot_model\n",
        "PATH = Path('/content/gdrive/My Drive/REU Materials/Data')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKDvTE4kAYgR"
      },
      "source": [
        "X_train = pd.read_csv(PATH/'train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "YNOYtgZm45xX",
        "outputId": "dd96cb9f-d325-4b6a-a749-12cb6bc3accf"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>EXT1</th>\n",
              "      <th>EXT2</th>\n",
              "      <th>EXT3</th>\n",
              "      <th>EXT4</th>\n",
              "      <th>EXT5</th>\n",
              "      <th>EXT6</th>\n",
              "      <th>EXT7</th>\n",
              "      <th>EXT8</th>\n",
              "      <th>EXT9</th>\n",
              "      <th>EXT10</th>\n",
              "      <th>EST1</th>\n",
              "      <th>EST2</th>\n",
              "      <th>EST3</th>\n",
              "      <th>EST4</th>\n",
              "      <th>EST5</th>\n",
              "      <th>EST6</th>\n",
              "      <th>EST7</th>\n",
              "      <th>EST8</th>\n",
              "      <th>EST9</th>\n",
              "      <th>EST10</th>\n",
              "      <th>AGR1</th>\n",
              "      <th>AGR2</th>\n",
              "      <th>AGR3</th>\n",
              "      <th>AGR4</th>\n",
              "      <th>AGR5</th>\n",
              "      <th>AGR6</th>\n",
              "      <th>AGR7</th>\n",
              "      <th>AGR8</th>\n",
              "      <th>AGR9</th>\n",
              "      <th>AGR10</th>\n",
              "      <th>CSN1</th>\n",
              "      <th>CSN2</th>\n",
              "      <th>CSN3</th>\n",
              "      <th>CSN4</th>\n",
              "      <th>CSN5</th>\n",
              "      <th>CSN6</th>\n",
              "      <th>CSN7</th>\n",
              "      <th>CSN8</th>\n",
              "      <th>CSN9</th>\n",
              "      <th>CSN10</th>\n",
              "      <th>OPN1</th>\n",
              "      <th>OPN2</th>\n",
              "      <th>OPN3</th>\n",
              "      <th>OPN4</th>\n",
              "      <th>OPN5</th>\n",
              "      <th>OPN6</th>\n",
              "      <th>OPN7</th>\n",
              "      <th>OPN8</th>\n",
              "      <th>OPN9</th>\n",
              "      <th>OPN10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>631052</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>770974</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>811924</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>964914</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>691563</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  EXT1  EXT2  EXT3  EXT4  ...  OPN6  OPN7  OPN8  OPN9  OPN10\n",
              "0      631052   0.6   0.8   0.4   0.8  ...   0.4   0.8   0.2   0.6    0.6\n",
              "1      770974   0.2   0.2   1.0   1.0  ...   0.2   1.0   0.6   0.6    0.6\n",
              "2      811924   0.2   0.6   0.8   0.6  ...   0.6   1.0   0.8   1.0    0.4\n",
              "3      964914   0.4   0.6   0.8   0.6  ...   0.2   0.8   0.6   0.8    0.8\n",
              "4      691563   0.4   1.0   0.6   1.0  ...   0.2   0.8   0.8   1.0    1.0\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I45myoa21sK5",
        "outputId": "fa3e2a5f-646d-4f5e-c852-1bbf8f73b72f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(709490, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3FT7fYtAzrb",
        "outputId": "d1e148da-d0f0-4095-951a-cd5d57641159"
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'EXT1', 'EXT2', 'EXT3', 'EXT4', 'EXT5', 'EXT6', 'EXT7',\n",
              "       'EXT8', 'EXT9', 'EXT10', 'EST1', 'EST2', 'EST3', 'EST4', 'EST5', 'EST6',\n",
              "       'EST7', 'EST8', 'EST9', 'EST10', 'AGR1', 'AGR2', 'AGR3', 'AGR4', 'AGR5',\n",
              "       'AGR6', 'AGR7', 'AGR8', 'AGR9', 'AGR10', 'CSN1', 'CSN2', 'CSN3', 'CSN4',\n",
              "       'CSN5', 'CSN6', 'CSN7', 'CSN8', 'CSN9', 'CSN10', 'OPN1', 'OPN2', 'OPN3',\n",
              "       'OPN4', 'OPN5', 'OPN6', 'OPN7', 'OPN8', 'OPN9', 'OPN10'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNRHlnTK_3-p"
      },
      "source": [
        "X_train.drop('Unnamed: 0', axis = 1, inplace = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z699HnpgA-f_"
      },
      "source": [
        "X_train = X_train.to_numpy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lzB16oxoCaK",
        "outputId": "b380ef8a-c281-4487-810a-ddeb037d3dd2"
      },
      "source": [
        "'''  \n",
        "VAE Code:\n",
        "          Encoder with n inputs\n",
        "          n ==> representing the number of questions/ items\n",
        "\n",
        "          No convolutional layers(used mainly with images), does not make sense since we are looking at a 1 dim vector\n",
        "          No flatten\n",
        "\n",
        "          Make a your own class file to represent the model at the start to streamline how the data is used\n",
        "\n",
        "          Use sequential ==> sequential can only release 1 output\n",
        "          \n",
        "          Look @ R folder\n",
        "\n",
        "          Two parts ==> encoder and decoder both sequential with dense layers input 50 ==> latent 2 ==> output 50\n",
        "\n",
        "          keep sampling\n",
        "'''\n",
        "#latent == num of traits??\n",
        "traits = 5\n",
        "latent_dim = 2\n",
        "questions = 10\n",
        "n = 50\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "                      Dense(traits, input_shape = (n, ), activation = 'relu', kernel_initializer='random_normal', bias_initializer='random_normal', name = 'latent'),\n",
        "                      #Dense(n, kernel_initializer='random_normal', bias_initializer='random_normal', name = 'output')\n",
        "                      ],\n",
        "                      name = 'model'\n",
        "                      )\n",
        "\n",
        "print(model.weights)\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'latent/kernel:0' shape=(50, 5) dtype=float32, numpy=\n",
            "array([[-0.0107991 ,  0.05356121, -0.0206395 , -0.07952619,  0.00069694],\n",
            "       [ 0.00189124,  0.00977674,  0.0607142 , -0.01746952,  0.01818673],\n",
            "       [-0.03303881,  0.03298327, -0.00092266,  0.0081782 ,  0.10745352],\n",
            "       [-0.05541299, -0.02287273, -0.03860935,  0.08328684,  0.02557985],\n",
            "       [ 0.05651274,  0.03257357,  0.04660131,  0.01202055, -0.03032109],\n",
            "       [-0.0140203 , -0.0254561 , -0.01660327,  0.05766572, -0.01270096],\n",
            "       [-0.01059559, -0.00079614,  0.01678194,  0.02779692,  0.03731912],\n",
            "       [ 0.00310751, -0.10735003, -0.00960064,  0.07472967, -0.09775484],\n",
            "       [ 0.06417269, -0.01308109, -0.01179343,  0.07061881, -0.00345754],\n",
            "       [ 0.02389939,  0.01154206,  0.06305439,  0.01669298, -0.01663616],\n",
            "       [ 0.03970646,  0.03310248, -0.04606347, -0.00981627, -0.05572474],\n",
            "       [ 0.06767177,  0.04819569,  0.03052004, -0.05308002, -0.0982243 ],\n",
            "       [-0.01313016, -0.06387569, -0.03875872,  0.13964991, -0.06962445],\n",
            "       [-0.02837406, -0.02945806, -0.05120344, -0.02351085, -0.07590178],\n",
            "       [ 0.0306638 , -0.03339403, -0.0199964 , -0.08331957,  0.04293963],\n",
            "       [-0.00760505, -0.02055848, -0.07563902, -0.03019758, -0.03015956],\n",
            "       [-0.03778646, -0.05324018, -0.0028217 , -0.06256836,  0.00638981],\n",
            "       [-0.06616508,  0.00683466, -0.02551124,  0.05792358,  0.05762232],\n",
            "       [-0.05040691, -0.00402405,  0.04274093, -0.04201001, -0.0271097 ],\n",
            "       [-0.01712262, -0.03353113,  0.01569328,  0.02559387, -0.03922538],\n",
            "       [-0.04625187, -0.00182912,  0.02057808, -0.07199869, -0.07684325],\n",
            "       [ 0.11436898, -0.02446091,  0.02393553, -0.01468462,  0.02782654],\n",
            "       [ 0.08751258, -0.00172519,  0.01508471,  0.00180748,  0.03291652],\n",
            "       [-0.00053101, -0.02032701, -0.02102129,  0.0242175 ,  0.01449668],\n",
            "       [ 0.08218112, -0.03785045,  0.00217438, -0.01498465, -0.01659806],\n",
            "       [ 0.02697806,  0.00641903,  0.06176493, -0.03952238, -0.01794674],\n",
            "       [ 0.11392411, -0.00661988, -0.00888366, -0.01915267, -0.06084762],\n",
            "       [ 0.02355229, -0.01861489,  0.07553478,  0.04321302, -0.00151064],\n",
            "       [ 0.07131528,  0.03747797, -0.02405197, -0.02443293,  0.07162844],\n",
            "       [-0.04247197,  0.03013625,  0.02303027, -0.05001352,  0.02736105],\n",
            "       [-0.02968471, -0.05868731,  0.02293282,  0.03745616,  0.00262852],\n",
            "       [ 0.01534875,  0.10037261,  0.00389547,  0.01708627, -0.03235703],\n",
            "       [ 0.07048427, -0.02287323,  0.13472591,  0.03624215, -0.02642997],\n",
            "       [-0.01918231,  0.00825041,  0.06900474,  0.11598724, -0.0214977 ],\n",
            "       [ 0.07589561,  0.0450809 ,  0.07288489,  0.02361872,  0.0044524 ],\n",
            "       [-0.05429298,  0.02899565, -0.00650115, -0.01651505, -0.02933527],\n",
            "       [-0.03609066,  0.038065  , -0.06801233, -0.07901306, -0.05424169],\n",
            "       [-0.01748939, -0.01608915, -0.02228038,  0.01998511, -0.05623346],\n",
            "       [-0.02599265,  0.09240957, -0.06077213, -0.07022281,  0.0054966 ],\n",
            "       [ 0.05762969, -0.02114009, -0.00537938,  0.02157336,  0.02546882],\n",
            "       [ 0.08745085, -0.03030442,  0.03960957, -0.11840887, -0.0339701 ],\n",
            "       [ 0.01718578, -0.02754599, -0.05021966,  0.01185708,  0.04977174],\n",
            "       [-0.03249051,  0.00115342,  0.02185204, -0.0168664 ,  0.02029618],\n",
            "       [-0.01779579,  0.02167011, -0.03594495,  0.01660823, -0.05850013],\n",
            "       [ 0.06871253, -0.06450329, -0.02380531, -0.07612751, -0.01477859],\n",
            "       [ 0.05979235,  0.05770928, -0.0683308 ,  0.0410046 ,  0.04545375],\n",
            "       [ 0.03094747,  0.07603061, -0.01654885,  0.02036012, -0.00552849],\n",
            "       [ 0.01468468,  0.0509613 , -0.04915161, -0.05389429,  0.02575115],\n",
            "       [-0.00112378, -0.0123511 , -0.1326609 ,  0.03165218,  0.08468522],\n",
            "       [ 0.06406452, -0.09448063, -0.01591328, -0.011233  ,  0.02150845]],\n",
            "      dtype=float32)>, <tf.Variable 'latent/bias:0' shape=(5,) dtype=float32, numpy=\n",
            "array([-0.0127695 ,  0.04741394,  0.02365122, -0.03109442, -0.04770922],\n",
            "      dtype=float32)>]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "latent (Dense)               (None, 5)                 255       \n",
            "=================================================================\n",
            "Total params: 255\n",
            "Trainable params: 255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "yt4guNSNRSiL",
        "outputId": "95e2f602-0f70-4375-8ff8-e5d26d93a7d2"
      },
      "source": [
        " plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "t2XSauoXLWrV",
        "outputId": "c4e63a8e-4d38-4552-98ea-97ad852a4abf"
      },
      "source": [
        "#x_train = np.expand_dims(X_train, -1)\n",
        "#print(X_train.shape)\n",
        "\n",
        "model.compile(optimizer= 'Adam')\n",
        "model.fit(X_train, epochs=30, batch_size=128)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e84c9733aeeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:774 train_step  *\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:530 minimize  **\n        return self.apply_gradients(grads_and_vars, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:630 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/utils.py:76 filter_empty_gradients\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['latent/kernel:0', 'latent/bias:0'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfj3Zp-1pxbt"
      },
      "source": [
        "'''\n",
        "Test code for functional structure VAE\n",
        "\n",
        "encoder_inputs = Input(shape = (n, ))\n",
        "x = Dense(100, activation=\"relu\")(encoder_inputs)\n",
        "x = Dense(60, activation=\"relu\")(x)\n",
        "x = Dense(10, activation = 'relu')(x)\n",
        "\n",
        "\n",
        "#latent/ bottleneck\n",
        "z_mean = Dense(latent_dim, name = \"z_mean\")(x)\n",
        "z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW3Ci60pox0M"
      },
      "source": [
        "'''\n",
        "latent_inputs = Input(shape = (latent_dim, ))\n",
        "x = Dense(100, activation=\"relu\")(latent_inputs)\n",
        "x = Dense(60, activation=\"relu\")(x)\n",
        "decoder_outputs = Dense(50, activation=\"relu\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "465jdiP1plck"
      },
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "  #computing the gradient with GradientTape\n",
        "    def train_step(self, data):\n",
        "        with GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW3TvBiRmpJ4"
      },
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}